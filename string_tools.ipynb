{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate lexical density of this string:  0.5555555555555556\n",
      "This text has an average lexical density\n"
     ]
    }
   ],
   "source": [
    "class string_tools:\n",
    "    \n",
    "    def count(string):\n",
    "       \n",
    "        lower_string = string.lower() #makes the letters all lower case \n",
    "        string_list = list(lower_string) #splitting the letters in a string, making them into a list\n",
    "        alphabet_list = list('abcdefghijklmnopqrstuvwxyz') \n",
    "        count = 0 #counter varliables\n",
    "        blank_count = 0\n",
    "        for i in string_list:\n",
    "            if i in alphabet_list:\n",
    "                count += 1  #counts all letters\n",
    "            else:\n",
    "                blank_count += 1 #counts all spaces\n",
    "        print(\"there are\", count, \"letters in the string and\", blank_count, \"spaces in the string\")\n",
    "        \n",
    "    def aux(string):\n",
    "       \n",
    "        lower_string = string.lower()#makes the letters all lower case \n",
    "        split_list = lower_string.split() #splitting the letters in a string, making them into a list- working with words\n",
    "        \n",
    "        auxiliary_verbs = ['do', 'has', 'will', 'is', 'has been','did']\n",
    "\n",
    "        count = 0 #counter varliables\n",
    "       \n",
    "        for i in split_list:\n",
    "            if i in auxiliary_verbs:\n",
    "                count += 1\n",
    "        \n",
    "        if count > 1:\n",
    "            print(\"There are\", count, \"auxiliary verbs in your string\")\n",
    "        else:\n",
    "            print(\"there is 1 auxiliary verb in your string \")\n",
    "    \n",
    "    def lexical_density(string):\n",
    "        \n",
    "        #Lexical density is defined as the number of lexical words (or content words) divided by the total number of words,\n",
    "        \n",
    "        # we find content words by taking the total amount of words and subtractin the function words\n",
    "        \n",
    "        function_words = ['a', 'about','above','after','after','again','against','ago','ahead','all' ,'almost','almost','along','already','also','although','always','am','among','an','and','any','are','around','as','at','away' \n",
    "\n",
    "'backward','backwards','be', 'because','before','behind', 'below', 'beneath','beside','between','both','but', 'by ',\n",
    "\n",
    "'can','cannot', 'cause' ,'cos','could','despite', 'did', 'do', 'does','down', 'during',\n",
    "\n",
    "'each', 'either', 'even', 'ever', 'every', 'except', 'for', 'forward', 'from', 'had', 'have', 'he', 'her', ' here','hers', 'herself', 'him', 'himself', 'his ', 'how', 'however', 'I',\n",
    "\n",
    "'if', 'in', 'inside', 'inspite','instead', 'into', 'is' ,'it', 'its', 'itself', 'just', 'will','shall', 'least', 'less','like',\n",
    "\n",
    "'them','many','may', 'me', 'might', 'mine','more', 'most','much', 'must', 'my', 'myself','near', 'need', 'needs', 'neither','never','no', 'none', 'nor', 'not','now',\n",
    "\n",
    "'of','off', 'often', 'on', 'once', 'only', 'onto', 'or','ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over ','past', 'perhaps', \n",
    "\n",
    "'quite', ' rather', 'seldom',' several', 'shall', 'she', 'should', 'since', 'so', 'some', 'sometimes', 'soon', \n",
    "\n",
    "'than', 'that', 'the', 'their', 'theirs', 'them', ' themselves ', 'then',' there ', 'therefore ', 'these ', 'they ', 'this', 'those', 'though', 'through', 'thus', 'till' ,'to', ' together', 'too','towards',\n",
    "\n",
    "'under', 'unless','until', 'up', 'upon', 'us',' used', 'usually',\n",
    "\n",
    "' very','was','we', 'well', 'were ', 'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whom',  'whose', 'why','will', 'with', 'without', 'would',\n",
    "\n",
    "'yet', 'you', 'your ', 'yours ', 'yourself', 'yourselves']\n",
    "        \n",
    "        lower_string = string.lower()#makes the letters all lower case \n",
    "        split_list = lower_string.split() #splitting the letters in a string, making them into a list- working with words\n",
    "        count = 0\n",
    "        function_word_count = 0\n",
    "        for i in split_list:\n",
    "            count += 1\n",
    "            if i in function_words:\n",
    "                function_word_count += 1\n",
    "        \n",
    "        content_word_count = count - function_word_count\n",
    "        lexical_density = content_word_count / count\n",
    "        print(\"The approximate lexical density of this string: \", lexical_density)\n",
    "        if lexical_density < 0.4:\n",
    "            print(\"This text is not lexically dense \")\n",
    "        elif 0.4 <  lexical_density < 0.6:\n",
    "            print(\"This text has an average lexical density\")\n",
    "        elif lexical_density > 0.6:\n",
    "            print(\"This text has a high lexical density\")\n",
    "            \n",
    "    def \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "            \n",
    "       \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
